% Auto-generated LaTeX tables for JAIR paper (v2: LLaMA + GPT-4)
% Generated from 330 experimental runs

% === table2_main_results_v2 ===
\begin{table*}[t]
\centering
\caption{Output variability across experimental conditions for LLaMA~3 8B (local) and GPT-4 (API). Mean over 5~abstracts. EMR = Exact Match Rate, NED = Normalized Edit Distance, ROUGE-L = word-level LCS F1.}
\label{tab:variability-results}
\small
\begin{tabular}{@{}lllccc@{}}
\toprule
\textbf{Model} & \textbf{Task} & \textbf{Condition} & \textbf{EMR}$\uparrow$ & \textbf{NED}$\downarrow$ & \textbf{ROUGE-L}$\uparrow$ \\
\midrule
  \multirow{9}{*}{\rotatebox[origin=c]{90}{LLaMA~3 8B}} & Summarization & C1 (fixed seed, $t{=}0$) & 0.840 & 0.0148 & 0.9823 \\
   &  & C2 (var.\ seeds, $t{=}0$) & 0.840 & 0.0148 & 0.9823 \\
   &  & C3 ($t{=}0.0$) & 0.733 & 0.0247 & 0.9706 \\
   &  & C3 ($t{=}0.3$) & 0.000 & 0.2289 & 0.7820 \\
   &  & C3 ($t{=}0.7$) & 0.000 & 0.4323 & 0.5550 \\
\cmidrule{2-6}
   & Extraction & C1 (fixed seed, $t{=}0$) & \textbf{1.000} & \textbf{0.0000} & \textbf{1.0000} \\
   &  & C2 (var.\ seeds, $t{=}0$) & \textbf{1.000} & \textbf{0.0000} & \textbf{1.0000} \\
   &  & C3 ($t{=}0.0$) & \textbf{1.000} & \textbf{0.0000} & \textbf{1.0000} \\
   &  & C3 ($t{=}0.3$) & 0.133 & 0.1883 & 0.8458 \\
   &  & C3 ($t{=}0.7$) & 0.000 & 0.3031 & 0.7447 \\
\midrule
  \multirow{8}{*}{\rotatebox[origin=c]{90}{GPT-4 (API)}} & Summarization & C2 (var.\ seeds, $t{=}0$) & 0.200 & 0.0718 & 0.9295 \\
   &  & C3 ($t{=}0.0$) & 0.000 & 0.0778 & 0.9248 \\
   &  & C3 ($t{=}0.3$) & 0.000 & 0.1721 & 0.8052 \\
   &  & C3 ($t{=}0.7$) & 0.000 & 0.3598 & 0.6143 \\
\cmidrule{2-6}
   & Extraction & C2 (var.\ seeds, $t{=}0$) & 0.520 & 0.0343 & 0.9748 \\
   &  & C3 ($t{=}0.0$) & 0.333 & 0.0257 & 0.9770 \\
   &  & C3 ($t{=}0.3$) & 0.400 & 0.0679 & 0.9413 \\
   &  & C3 ($t{=}0.7$) & 0.000 & 0.1648 & 0.8557 \\
\bottomrule
\end{tabular}
\end{table*}

% === table3_overhead_v2 ===

\begin{table}[t]
\centering
\caption{Protocol overhead: logging time and storage costs for 330~runs (190 LLaMA~3 + 140 GPT-4).}
\label{tab:overhead}
\small
\begin{tabular}{@{}lrl@{}}
\toprule
\textbf{Metric} & \textbf{Value} & \textbf{Unit} \\
\midrule
\multicolumn{3}{l}{\textit{Logging time overhead}} \\
\quad Mean per run & 33.56 $\pm$ 5.68 & ms \\
\quad Min / Max & 12.85 / 51.20 & ms \\
\quad Total (330 runs) & 11074 & ms \\
\quad Mean overhead ratio & 0.694\% & of inference time \\
\quad Max overhead ratio & 1.621\% & of inference time \\
\midrule
\multicolumn{3}{l}{\textit{Storage overhead}} \\
\quad Run logs (330 files) & 1382 & KB \\
\quad PROV documents (331 files) & 1736 & KB \\
\quad Run Cards (330 files) & 454 & KB \\
\quad Total output & 4.87 & MB \\
\bottomrule
\end{tabular}
\end{table}


% === table_model_comparison ===
\begin{table}[t]
\centering
\caption{Reproducibility comparison: LLaMA~3 8B (local) vs.\ GPT-4 (API) under greedy decoding ($t{=}0$). GPT-4 shows significantly lower reproducibility due to server-side non-determinism.}
\label{tab:model-comparison}
\small
\begin{tabular}{@{}llcc@{}}
\toprule
\textbf{Task} & \textbf{Metric} & \textbf{LLaMA~3 8B} & \textbf{GPT-4} \\
\midrule
  Summarization & EMR & 0.840 & 0.200 \\
   & NED & 0.0148 & 0.0718 \\
   & ROUGE-L & 0.9823 & 0.9295 \\
\midrule
  Extraction & EMR & 1.000 & 0.520 \\
   & NED & 0.0000 & 0.0343 \\
   & ROUGE-L & 1.0000 & 0.9748 \\
\bottomrule
\end{tabular}
\end{table}

