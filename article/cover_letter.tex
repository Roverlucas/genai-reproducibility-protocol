\documentclass[11pt]{letter}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\usepackage{parskip}

\signature{Lucas Rover and Yara de Souza Tadano\\
Programa de P\'os-Gradua\c{c}\~ao em Engenharia Mec\^anica\\
UTFPR -- Universidade Tecnol\'ogica Federal do Paran\'a\\
Ponta Grossa, Paran\'a, Brazil\\
\texttt{lucasrover@utfpr.edu.br}, \texttt{yaratadano@utfpr.edu.br}}

\address{Lucas Rover and Yara de Souza Tadano\\
UTFPR -- Universidade Tecnol\'ogica Federal do Paran\'a\\
Ponta Grossa, Paran\'a, Brazil}

\date{February 7, 2026}

\begin{document}

\begin{letter}{Professors J.\ Christopher Beck, Edith Elkind, and Mykel Kochenderfer\\
Editors-in-Chief\\
Journal of Artificial Intelligence Research (JAIR)}

\opening{Dear Professors Beck, Elkind, and Kochenderfer,}

We are pleased to submit the manuscript entitled \textbf{``Hidden Non-Determinism in Large Language Model APIs: A Lightweight Provenance Protocol for Reproducible Generative AI Research''} for consideration for publication in the \textit{Journal of Artificial Intelligence Research}.

This work addresses a timely and critical challenge in AI research: the reproducibility of studies that rely on large language model outputs. While the AI reproducibility crisis has been widely documented, existing experiment-tracking tools were not designed for the specific challenges of generative text outputs. The paper makes three contributions:

\begin{enumerate}
    \item \textbf{A lightweight protocol} introducing novel documentation artifacts---Prompt Cards and Run Cards---built on the W3C PROV data model for machine-readable provenance graphs.

    \item \textbf{An empirical evaluation} through 1,864 controlled experiments with LLaMA~3 8B (local) and GPT-4 (API) across 30 scientific abstracts, revealing a striking reproducibility gap between local and API-based inference. Notably, GPT-4 achieves only 23\% exact match rate for summarization under nominally deterministic settings---a finding that is invisible without systematic logging.

    \item \textbf{A reference implementation} in Python with all experimental data publicly available for independent verification.
\end{enumerate}

We believe this work is well-suited for JAIR for several reasons: (a) it addresses a foundational methodological issue affecting all AI research that uses generative models; (b) it provides rigorous empirical evidence rather than purely conceptual arguments; (c) the protocol and tools are immediately practical for the AI research community; and (d) the paper's scope---spanning reproducibility, provenance, and empirical methodology---aligns with JAIR's broad interest in AI foundations.

The protocol adds negligible overhead (0.545\% of inference time, approximately 4~KB per run) while providing complete audit trails, tamper detection via cryptographic hashing, and interoperable provenance graphs. We hope this work will contribute to raising the bar for reproducibility in generative AI research.

This manuscript has not been published elsewhere and is not under consideration by any other journal. All authors have approved the manuscript and agree with its submission to JAIR.

\closing{Sincerely,}

\end{letter}
\end{document}
