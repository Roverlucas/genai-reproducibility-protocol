\begin{table}[t]
\centering
\caption{Reproducibility comparison: LLaMA~3 8B (local) vs.\ GPT-4 (API) under greedy decoding ($t{=}0$). GPT-4 shows significantly lower reproducibility due to server-side non-determinism.}
\label{tab:model-comparison}
\small
\begin{tabular}{@{}llcc@{}}
\toprule
\textbf{Task} & \textbf{Metric} & \textbf{LLaMA~3 8B} & \textbf{GPT-4} \\
\midrule
  Summarization & EMR & 0.947 & 0.230 \\
   & NED & 0.0050 & 0.1365 \\
   & ROUGE-L & 0.9945 & 0.8695 \\
\midrule
  Extraction & EMR & 0.987 & 0.443 \\
   & NED & 0.0031 & 0.0724 \\
   & ROUGE-L & 0.9966 & 0.9384 \\
\bottomrule
\end{tabular}
\end{table}