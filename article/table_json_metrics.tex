\begin{table*}[t]
\centering
\caption{JSON extraction quality metrics by model and condition. \textit{Raw Valid} = output parses directly as JSON; \textit{Extracted Valid} = JSON extracted via regex from outputs containing preamble text; \textit{Schema} = all five expected fields present; \textit{Field EMR} = within-abstract pairwise exact match across runs for each extracted field, averaged over abstracts (see Section~\ref{app:json-quality} for interpretation). LLaMA~3 always prepends introductory text (e.g., ``Here is the extracted information in JSON format:''), yielding 0\% raw validity but near-perfect extracted validity at $t{=}0$.}
\label{tab:json-metrics}
\small
\begin{tabular}{@{}llccccccccc@{}}
\toprule
\textbf{Model} & \textbf{Cond.} & \textbf{Raw} & \textbf{Extr.} & \textbf{Schema} & \multicolumn{5}{c}{\textbf{Within-Abstract Field EMR}} & \textbf{Overall} \\
\cmidrule(lr){6-10}
 & & \textbf{Valid} & \textbf{Valid} & \textbf{Compl.} & obj & meth & key\_r & mod/sys & bench & \textbf{Field EMR} \\
\midrule
\multirow{5}{*}{\rotatebox[origin=c]{90}{LLaMA~3}} & C1 ($t{=}0$)   & 0\% & 100\% & 100\% & 0.987 & 0.987 & 0.987 & 1.000 & 0.987 & 0.989 \\
 & C2 ($t{=}0$)   & 0\% & 100\% & 100\% & 0.987 & 0.987 & 0.987 & 1.000 & 0.987 & 0.989 \\
 & C3 ($t{=}0.0$) & 0\% & 100\% & 100\% & 0.978 & 0.978 & 0.978 & 1.000 & 0.978 & 0.982 \\
 & C3 ($t{=}0.3$) & 0\% & 97.8\% & 97.8\% & 0.747 & 0.460 & 0.552 & 0.862 & 0.805 & 0.685 \\
 & C3 ($t{=}0.7$) & 0\% & 92.2\% & 92.2\% & 0.522 & 0.167 & 0.267 & 0.611 & 0.711 & 0.456 \\
\midrule
\multirow{4}{*}{\rotatebox[origin=c]{90}{GPT-4}} & C2 ($t{=}0$) & 100\% & 100\% & 100\% & 0.773 & 0.667 & 0.637 & 0.893 & 0.863 & 0.767 \\
 & C3 ($t{=}0.0$) & 100\% & 100\% & 100\% & 0.833 & 0.571 & 0.667 & 0.905 & 0.810 & 0.757 \\
 & C3 ($t{=}0.3$) & 100\% & 100\% & 100\% & 0.405 & 0.262 & 0.452 & 0.762 & 0.690 & 0.514 \\
 & C3 ($t{=}0.7$) & 100\% & 100\% & 100\% & 0.137 & 0.157 & 0.255 & 0.667 & 0.725 & 0.388 \\
\bottomrule
\end{tabular}
\end{table*}
