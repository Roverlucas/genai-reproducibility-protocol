{
  "run_card_version": "1.0",
  "run_id": "gemma2_9b_rag_extraction_abs_007_C1_fixed_seed_rep2",
  "task_id": "rag_extraction",
  "task_category": "rag_structured_extraction",
  "prompt_card_ref": "prompt_card_rag_extraction_v1_0.json",
  "prompt_hash": "8954dea2db116d744a5abe2a65fef86fdf3a6f65e3087c482230edf777788243",
  "model_name": "gemma2:9b",
  "model_version": "9.2B",
  "weights_hash": "ff02c3702f322b9e075e9568332d96c0a7028002f1a5a056e0a6784320a4db0b",
  "model_source": "ollama-local",
  "inference_params": {
    "temperature": 0.0,
    "top_p": 1.0,
    "top_k": 0,
    "max_tokens": 1024,
    "decoding_strategy": "greedy",
    "seed": 42
  },
  "params_hash": "5f7d7b01f15d56320643fc4dd41f0fd4168b757a420e7c514e72a9a744f7391d",
  "interaction_regime": "single-turn-with-context",
  "retrieval_context": {
    "source": "simulated_retrieval",
    "query": "He et al. (2016) - Deep Residual Learning for Image Recognition (CVPR)",
    "retrieved_text": "Related work: VGGNet (Simonyan & Zisserman, 2015) showed benefits of increased depth up to 19 layers. GoogLeNet (Szegedy et al., 2015) used inception modules. The ImageNet Large Scale Visual Recognition Challenge (ILSVRC) has been the primary benchmark for image classification since 2010.",
    "n_chunks": 1
  },
  "environment_hash": "cd45d42899c58da3d18196ae6b15aa5d337dd0cc98fea1587207f261f93df6a1",
  "code_commit": "e57ae1950438395fa23acd727b18e0be41834a65",
  "environment_details": {
    "os": "Darwin",
    "python_version": "3.14.3",
    "architecture": "arm64"
  },
  "timestamp_start": "2026-02-10T12:51:02.623180+00:00",
  "timestamp_end": "2026-02-10T12:51:14.066221+00:00",
  "execution_duration_ms": 11443.04,
  "output_hash": "2d773053ea5355e5bcd4cee819a85168dc8199e817cd8f4ac59e0e9bcd81fdb4",
  "output_metrics": {},
  "logging_overhead_ms": 31.39,
  "storage_kb": 4.74,
  "researcher_id": "lucas_rover",
  "affiliation": "UTFPR - Universidade Tecnologica Federal do Parana",
  "errors": []
}